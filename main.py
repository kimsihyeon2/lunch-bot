import requests
from bs4 import BeautifulSoup
import datetime
import logging
import sys
import re
from typing import List, Optional

# --- 1. ë¡œê¹… ì„¤ì • (SOTA: print ëŒ€ì‹  logging ì‚¬ìš©) ---
# ë¡œê·¸ í¬ë§·: [ì‹œê°„] [ë¡œê·¸ë ˆë²¨] ë©”ì‹œì§€ -> ê°€ë…ì„± í™•ë³´
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger("LunchCrawler")

class NaverCafeCrawler:
    """
    ë„¤ì´ë²„ ì¹´í˜ ê²Œì‹œê¸€ í¬ë¡¤ëŸ¬ (Session í™œìš© ë° ì˜ˆì™¸ ì²˜ë¦¬ ê°•í™”)
    """
    
    # ë„¤ì´ë²„ ë´‡ ì°¨ë‹¨ ë°©ì§€ë¥¼ ìœ„í•œ í—¤ë”
    DEFAULT_HEADERS = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Referer': 'https://cafe.naver.com/',
        'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7'
    }

    def __init__(self, club_id: int, menu_id: int):
        self.club_id = club_id
        self.menu_id = menu_id
        # SOTA: ë§¤ ìš”ì²­ë§ˆë‹¤ ì—°ê²°ì„ ë§ºì§€ ì•Šê³  Sessionì„ ì¬ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒ
        self.session = requests.Session()
        self.session.headers.update(self.DEFAULT_HEADERS)
        
        # ê²€ìƒ‰í•  ë‚ ì§œ í‚¤ì›Œë“œ ìƒì„± (ì˜¤ëŠ˜ ë‚ ì§œ)
        self.target_keywords = self._generate_date_keywords()

    def _generate_date_keywords(self) -> List[str]:
        """ì˜¤ëŠ˜ ë‚ ì§œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰í•  ë‹¤ì–‘í•œ í¬ë§·ì˜ í‚¤ì›Œë“œ ìƒì„±"""
        now = datetime.datetime.now()
        keywords = [
            now.strftime("%mì›”%dì¼"),    # ì˜ˆ: 12ì›”19ì¼
            now.strftime("%mì›” %dì¼"),   # ì˜ˆ: 12ì›” 19ì¼
            now.strftime("%-mì›” %-dì¼")  # ì˜ˆ: 9ì›” 5ì¼ (ìœˆë„ìš°ì—ì„œëŠ” # ëŒ€ì‹  - ì‚¬ìš© ì£¼ì˜)
        ]
        # ë¦¬ëˆ…ìŠ¤/ìœ ë‹‰ìŠ¤ í™˜ê²½ í˜¸í™˜ì„±ì„ ìœ„í•œ ì²˜ë¦¬
        if sys.platform != 'win32':
             keywords.append(now.strftime("%-mì›”%-dì¼"))
             
        logger.info(f"ğŸ“… ì˜¤ëŠ˜ ê²€ìƒ‰ ëŒ€ìƒ ë‚ ì§œ í‚¤ì›Œë“œ: {keywords}")
        return keywords

    def fetch_article_list(self) -> str:
        """ê²Œì‹œê¸€ ëª©ë¡ HTML ê°€ì ¸ì˜¤ê¸°"""
        url = "https://cafe.naver.com/ArticleList.nhn"
        params = {
            'search.clubid': self.club_id,
            'search.menuid': self.menu_id,
            'search.boardtype': 'L', # ë¦¬ìŠ¤íŠ¸í˜• ê²Œì‹œíŒ
            'userDisplay': 50        # í•œ ë²ˆì— ë§ì´ ê°€ì ¸ì˜¤ê¸°
        }
        
        try:
            response = self.session.get(url, params=params, timeout=10)
            response.raise_for_status()
            
            # ì¸ì½”ë”© ìë™ ê°ì§€ ë° ì„¤ì • (euc-kr, cp949 ëŒ€ì‘)
            response.encoding = response.apparent_encoding if response.apparent_encoding else 'utf-8'
            
            return response.text
        except requests.exceptions.RequestException as e:
            logger.error(f"âŒ ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ì‹¤íŒ¨: {e}")
            raise

    def parse_and_find_menus(self, html: str):
        """HTML íŒŒì‹± ë° ë©”ë‰´ ì°¾ê¸°"""
        soup = BeautifulSoup(html, 'html.parser')
        
        # ArticleList.nhnì˜ í‘œì¤€ êµ¬ì¡°: div.article-board > table > tbody > tr
        # ìœ ì—°ì„±ì„ ìœ„í•´ a.article íƒœê·¸ë¥¼ ì§ì ‘ ì°¾ìŠµë‹ˆë‹¤.
        articles = soup.select('a.article')
        
        if not articles:
            logger.warning("âš ï¸ ê²Œì‹œê¸€ ëª©ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (HTML êµ¬ì¡° ë³€ê²½ ë˜ëŠ” ë´‡ ì°¨ë‹¨ ì˜ì‹¬)")
            # ë””ë²„ê¹…ì„ ìœ„í•´ HTML ì¼ë¶€ ë¡œê¹… (í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)
            # logger.debug(soup.prettify()[:500])
            return

        found_count = 0
        logger.info(f"ğŸ” ìµœì‹  ê²Œì‹œê¸€ {len(articles)}ê°œë¥¼ ìŠ¤ìº”í•©ë‹ˆë‹¤...")

        for article in articles:
            title = article.get_text(strip=True)
            link = "https://cafe.naver.com" + article.get('href')
            
            # ì œëª©ì— ë‚ ì§œ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            if any(keyword in title for keyword in self.target_keywords):
                self._log_success(title, link)
                found_count += 1
            else:
                # ë””ë²„ê¹…: ì˜¤ëŠ˜ ë‚ ì§œê°€ ì•„ë‹ˆë”ë¼ë„ ì–´ë–¤ ê¸€ì„ ì½ê³  ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ
                # logger.debug(f"PASS (ë‚ ì§œë¶ˆì¼ì¹˜): {title}")
                pass

        if found_count == 0:
            logger.warning("âŒ [ê²°ê³¼ ì—†ìŒ] ì˜¤ëŠ˜ ë‚ ì§œì˜ ë©”ë‰´ ê²Œì‹œê¸€ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            logger.info("ğŸ‘‰ íŒ: ê²Œì‹œê¸€ ì œëª©ì— '12ì›” 19ì¼'ê³¼ ê°™ì€ ë‚ ì§œê°€ ì •í™•íˆ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        else:
            logger.info(f"ğŸ‰ ì´ {found_count}ê°œì˜ ì˜¤ëŠ˜ ì ì‹¬ ë©”ë‰´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

    def _log_success(self, title: str, link: str):
        """ì°¾ì€ ê²°ê³¼ë¥¼ ì˜ˆì˜ê²Œ ì¶œë ¥"""
        print("\n" + "="*60)
        print(f"ğŸ± [ë°œê²¬] {title}")
        print(f"ğŸ”— ë§í¬: {link}")
        print("="*60 + "\n")

    def run(self):
        """ì „ì²´ ë¡œì§ ì‹¤í–‰"""
        logger.info("ğŸš€ ì ì‹¬ ë©”ë‰´ í¬ë¡¤ëŸ¬ ì‹œì‘")
        try:
            html = self.fetch_article_list()
            self.parse_and_find_menus(html)
        except Exception as e:
            logger.critical(f"ğŸ”¥ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
        finally:
            logger.info("ğŸ‘‹ í¬ë¡¤ëŸ¬ ì¢…ë£Œ")

# --- ì‹¤í–‰ë¶€ (Main) ---
if __name__ == "__main__":
    # ì‚¬ìš©ì ì„¤ì •ê°’ (ê¸°ì¡´ URL íŒŒë¼ë¯¸í„° ê¸°ë°˜)
    CLUB_ID = 30487307
    MENU_ID = 26
    
    bot = NaverCafeCrawler(club_id=CLUB_ID, menu_id=MENU_ID)
    bot.run()
