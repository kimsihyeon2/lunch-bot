import requests
from bs4 import BeautifulSoup
import datetime
import logging
import sys
import time

# --- ë¡œê¹… ì„¤ì • ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S',
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger("LunchCrawler")

class NaverCafeMobileCrawler:
    """
    ë„¤ì´ë²„ ì¹´í˜ ëª¨ë°”ì¼ ì›¹(m.cafe.naver.com) í¬ë¡¤ëŸ¬
    PC ë²„ì „ë³´ë‹¤ êµ¬ì¡°ê°€ ë‹¨ìˆœí•˜ê³  ì°¨ë‹¨ í™•ë¥ ì´ ë‚®ìŒ
    """
    
    def __init__(self, club_id: int, menu_id: int):
        self.club_id = club_id
        self.menu_id = menu_id
        self.session = requests.Session()
        
        # ëª¨ë°”ì¼ í™˜ê²½ì²˜ëŸ¼ ìœ„ì¥
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Linux; Android 10; K) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Mobile Safari/537.36',
            'Referer': f'https://m.cafe.naver.com/SectionArticleList.nhn?cafeId={club_id}&menuId={menu_id}',
            'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7'
        })
        
        self.target_keywords = self._generate_date_keywords()

    def _generate_date_keywords(self):
        now = datetime.datetime.now()
        # ëª¨ë°”ì¼ì—ì„œë„ ì œëª©ì— ë‚ ì§œê°€ ë“¤ì–´ê°€ëŠ” íŒ¨í„´ì€ ë™ì¼í•¨
        keywords = [
            now.strftime("%mì›”%dì¼"),    # 12ì›”19ì¼
            now.strftime("%mì›” %dì¼"),   # 12ì›” 19ì¼
            now.strftime("%-mì›” %-dì¼"), # 9ì›” 5ì¼ (Mac/Linux)
            now.strftime("%-mì›”%-dì¼")   # 9ì›”5ì¼ (Mac/Linux)
        ]
        if sys.platform == 'win32':
             # ìœˆë„ìš°ì—ì„œëŠ” %-m ì§€ì› ì•ˆ í•¨, ì˜ˆì™¸ ì²˜ë¦¬ ìƒëµ(ìœ„ì˜ í¬ë§·ìœ¼ë¡œ ì¶©ë¶„)
             pass
             
        logger.info(f"ğŸ“… ê²€ìƒ‰ í‚¤ì›Œë“œ: {keywords}")
        return keywords

    def fetch_list(self):
        # ëª¨ë°”ì¼ ì „ìš© URL
        url = "https://m.cafe.naver.com/SectionArticleList.nhn"
        params = {
            'cafeId': self.club_id,
            'menuId': self.menu_id
        }
        
        try:
            logger.info("ğŸ“¡ ë„¤ì´ë²„ ì¹´í˜(ëª¨ë°”ì¼) ì ‘ì† ì¤‘...")
            response = self.session.get(url, params=params, timeout=10)
            response.raise_for_status()
            return response.text
        except Exception as e:
            logger.error(f"âŒ ì ‘ì† ì‹¤íŒ¨: {e}")
            return None

    def parse(self, html):
        if not html: return

        soup = BeautifulSoup(html, 'html.parser')
        
        # ë””ë²„ê¹…: ì ‘ì†í•œ í˜ì´ì§€ ì œëª© í™•ì¸ (ë¡œê·¸ì¸ í˜ì´ì§€ë¡œ íŠ•ê²¼ëŠ”ì§€ í™•ì¸ìš©)
        page_title = soup.title.get_text(strip=True) if soup.title else "ì œëª©ì—†ìŒ"
        logger.info(f"ğŸ“„ ì ‘ì† í˜ì´ì§€ ì œëª©: {page_title}")

        # ëª¨ë°”ì¼ ë¦¬ìŠ¤íŠ¸ ì„ íƒì: ul.list_area > li
        articles = soup.select('ul.list_area > li')
        
        if not articles:
            # í˜¹ì‹œ ëª¨ë°”ì¼ ë ˆì´ì•„ì›ƒì´ ë‹¤ë¥¸ ê²½ìš° ëŒ€ë¹„ (ì¹´ë“œí˜• ë“±)
            articles = soup.select('div.list_area > div.board_box') 
            
        if not articles:
            logger.warning("âš ï¸ ê²Œì‹œê¸€ ëª©ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            # HTML êµ¬ì¡°ê°€ ë°”ë€Œì—ˆê±°ë‚˜ ì°¨ë‹¨ë˜ì—ˆì„ ë•Œ HTML ì¼ë¶€ ì¶œë ¥
            logger.debug(f"DEBUG HTML: {soup.prettify()[:500]}")
            return

        found_count = 0
        logger.info(f"ğŸ” ìµœì‹  ê¸€ {len(articles)}ê°œ ë¶„ì„ ì‹œì‘...")

        for item in articles:
            # ì œëª© íƒœê·¸ ì°¾ê¸° (ëª¨ë°”ì¼ êµ¬ì¡° ê¸°ì¤€)
            title_tag = item.select_one('strong.tit') or item.select_one('div.tit')
            
            if not title_tag:
                continue
                
            title = title_tag.get_text(strip=True)
            
            # ë§í¬ ì°¾ê¸°
            link_tag = item.select_one('a.txt_area') or item.select_one('a')
            link = "https://m.cafe.naver.com" + link_tag['href'] if link_tag else "ë§í¬ì—†ìŒ"

            # ì‘ì„±ì/ì‘ì„±ì¼ ë“± ì¶”ê°€ ì •ë³´ (ì˜µì…˜)
            date_tag = item.select_one('span.time')
            date_text = date_tag.get_text(strip=True) if date_tag else ""

            # í•„í„°ë§
            is_target = any(k in title for k in self.target_keywords)
            
            if is_target:
                self._print_menu(title, link, date_text)
                found_count += 1

        if found_count == 0:
            logger.info("ğŸ“­ ì˜¤ëŠ˜ ë‚ ì§œ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²Œì‹œê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            logger.info(f"ğŸ‰ ì´ {found_count}ê°œì˜ ë©”ë‰´ ë°œê²¬!")

    def _print_menu(self, title, link, date):
        print("\n" + "â”€"*50)
        print(f"ğŸ± ë©”ë‰´ ë°œê²¬: {title}")
        print(f"â° ì‘ì„±ì‹œê°„: {date}")
        print(f"ğŸ”— ë°”ë¡œê°€ê¸°: {link}")
        print("â”€"*50 + "\n")

    def run(self):
        html = self.fetch_list()
        self.parse(html)

if __name__ == "__main__":
    # íŒêµ í…Œí¬ë…¸ë°¸ë¦¬ êµ¬ë‚´ì‹ë‹¹ ì •ë³´ ê³µìœ  ì¹´í˜
    CLUB_ID = 30487307
    MENU_ID = 26
    
    bot = NaverCafeMobileCrawler(CLUB_ID, MENU_ID)
    bot.run()
